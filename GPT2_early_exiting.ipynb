{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "* Get early attention blocks\n",
        "* Use those blocks to predict the next token\n",
        "* For loop to iterate over all attention block predictions\n",
        "* Time how long it takes for each prediction\n",
        "* Add some kind of benchmark; plot layer vs accuracy"
      ],
      "metadata": {
        "id": "2olo3JXHt85i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup & loading model"
      ],
      "metadata": {
        "id": "j-PdEVP7wliZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "5mKuWV8_SV1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\", output_attentions=True, output_hidden_states=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")"
      ],
      "metadata": {
        "id": "7pxd2XIbwr51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_token(text, model, tokenizer):\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids=input_ids)\n",
        "\n",
        "    logits = output.logits[0, -1, :]\n",
        "    next_token_id = torch.argmax(logits).item()\n",
        "    next_token = tokenizer.decode(next_token_id)\n",
        "\n",
        "    return next_token"
      ],
      "metadata": {
        "id": "UKqFbGAL0Gs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Once upon a time\"\n",
        "next_token = predict_next_token(text, model, tokenizer)\n",
        "print(\"Next token prediction:\", next_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOtquB67zz0x",
        "outputId": "ff7df79c-b761-4af8-b269-199465a57826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next token prediction: ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get early attention blocks"
      ],
      "metadata": {
        "id": "gVkVtcDuwCcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hiddenstates_attn(text, model, tokenizer):\n",
        "  input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    output = model(input_ids=input_ids)\n",
        "  hidden_states = output.hidden_states\n",
        "  attentions = output.attentions\n",
        "  return hidden_states, attentions"
      ],
      "metadata": {
        "id": "4T6nRjFO0zHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden, attn = get_hiddenstates_attn(text, model, tokenizer)"
      ],
      "metadata": {
        "id": "tItJcm2zJGDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this always returns none; I am not sure why\n",
        "def get_next_token_from_hidden(text, hidden_states, attentions, layer):\n",
        "  logits = model.lm_head(hidden_states[layer])\n",
        "  next_token_logits = logits[:, -1, :]\n",
        "  probabilities = F.softmax(next_token_logits, dim=-1)\n",
        "  predicted_token_id = probabilities.argmax(dim=-1)\n",
        "  predicted_token = tokenizer.decode(predicted_token_id.tolist())\n",
        "  return predicted_token"
      ],
      "metadata": {
        "id": "zzOJaOVT5-Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(hidden)):\n",
        "  print(get_next_token_from_hidden(text, hidden, attn, i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tRB9tO2Pgpd",
        "outputId": "9dc835bc-5244-4c45-b615-2e85080b21a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use blocks to predict next token\n"
      ],
      "metadata": {
        "id": "6EzmO9rCwK6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "TBIJGSYIwQl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For loop over attention blocks"
      ],
      "metadata": {
        "id": "mg1ZxUFlwUC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "g0ViCYVpwYMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction time"
      ],
      "metadata": {
        "id": "_Kxsic9owZNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "-uztZm0swdah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Benchmark & plotting"
      ],
      "metadata": {
        "id": "n3fC0JoQwfmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "-mlf8BdYwjL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}